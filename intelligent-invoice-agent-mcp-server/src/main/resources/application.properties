spring.application.name=intelligent-invoice-agent-mcp-server

# Web Server Configuration
server.port=8081
spring.main.web-application-type=servlet
spring.main.banner-mode=off
spring.ai.mcp.server.name=intelligent-invoice-agent-mcp-server
spring.ai.mcp.server.version=0.0.1

llm.api.key=${LLM_API_KEY:}
# Default provider URL (change if you use Groq)
llm.api.url=${LLM_API_URL:https://api.openai.com/v1/chat/completions}
# Force a supported model to avoid using decommissioned models from environment variables
llm.model=gpt-4o-mini

# Logging - enable debug for our project to see detailed LLM logs
logging.level.root=INFO
logging.level.com.anupam=DEBUG


# Python API Configuration
python.api.url=http://localhost:8000/process-invoice
python.api.process-invoice-data-url=http://localhost:8000/process-invoice-data

# Email Configuration
email.host=outlook.office365.com
email.port=993
email.username=${email.username:}
email.password=${EMAIL_PASSWORD:}

# Google OAuth2 Configuration
google.client.id=${GOOGLE_CLIENT_ID:}
google.client.secret=${GOOGLE_CLIENT_SECRET:}
google.redirect.uri=${GOOGLE_REDIRECT_URI:}
google.refresh.token=${GOOGLE_REFRESH_TOKEN:}
google.pubsub.topic=${GOOGLE_PUB_SUB_TOPIC_NAME:}
google.push.endpoint=${GOOGLE_PUSH_ENDPOINT_URI:}

#Kafka Configuration
spring.kafka.bootstrap-servers=kafka-b351a54-anupam-85c8.g.aivencloud.com:10442
kafka.topic.invoice-response=push-analysis-data-topic

# Include Resilience4j Configuration
spring.profiles.include=resilience

